\chapter{Preliminary}

\section{Empirical Spectral Measure}

\begin{definition}[Empirical Spectral Measure]
	For a symmetric matrix $\bfM\in\bbR^{n\times n}$, the spectral measure or empirical spectral measure or empirical spectral distribution (ESD) $\mu_{\bfM}$ of $\bfM$ is defined as the normalized counting measure of the eigenvalues $\lambda_{1}(\bfM),\ldots,\lambda_{n}(\bfM)$ of $\bfM$, i.e.,
	\begin{equation}
		\mu_{\bfM}:=\frac{1}{n}\sum_{i=1}^{n}\delta_{\lambda_{i}(\bfM)}
	\end{equation}
	where $\delta_{x}$ is a Dirac measure for any (measurable) set, that
	\begin{equation*}
		\delta_{x}(A):=\mathbf{1}_{A}(x)=
		\begin{cases}
			0, & x\notin A \\
			1, & x\in A
		\end{cases}
	\end{equation*}
	Since $\int\mu_{\bfM}\left(\dif x\right)=1$, the spectral measure $\mu_{\bfM}$ of a matrix $\bfM\in\bbR^{n\times n}$ (random or not) is a probability measure.
\end{definition}

\begin{remark}
	Many important statistics in multivariate analysis can be expressed as functionals of the ESD, such as, for $\bfM$ be an $n\times n$ positive definite matrix, then
	\begin{equation}
		\operatorname{det}(\bfM)=\prod_{i=1}^{n}\lambda_{i}=\exp\left(n\int_{0}^{\infty}\log x\mu_{\bfM}(\dif x)\right)
	\end{equation}
\end{remark}

\section{Stieltjes Transform}

\begin{definition}[Resolvent]
	For a symmetric matrix $\bfM\in\bbR^{n\times n}$, the resolvent $\bfQ_{\bfM}(z)$ of $\bfM$ is defined as
	\begin{equation}
		\bfQ_{\bfM}(z):=\left(\bfM-z\mathbf{I}_{n}\right)^{-1}
	\end{equation}
	where $z\in\mathbb{C}$ not eigenvalue of $\bfM$.
\end{definition}

\begin{definition}[Stieltjes Transform]
	For a real probability measure $\mu$ with support $\operatorname{supp}(\mu)$, the Stieltjes transform $m_{\mu}(z)$ is defined as
	\begin{equation}
		m_{\mu}(z):=\int\frac{1}{t-z}\mu\left(\dif t\right)
	\end{equation}
	where $z\in\mathbb{C}\backslash\operatorname{supp}(\mu)$.
\end{definition}

\begin{property}
	The Stieltjes transform $m_{\mu}$ has numerous interesting properties:
	\begin{enumerate}
		\item it is complex analytic on its domain of definition $\mathbb{C} \backslash \operatorname{supp}(\mu)$.
		\item it is bounded $\left|m_{\mu}(z)\right|\leq 1/\operatorname{dist}(z,\operatorname{supp}(\mu))$.
		\item it satisfies $\Im[z]>0 \Rightarrow \Im[m(z)]>0$.
		\item it is an increasing function on all connected components of its restriction to $\bbR\backslash\operatorname{supp}(\mu)$. % (since $m_{\mu}^{\prime}(x)=\int(t-x)^{-2} \mu(d t)>0$)
		\item if $\operatorname{supp}(\mu)$ is bounded, $\lim_{x\rightarrow\pm\infty}m_{\mu}(x)=0$.
	\end{enumerate}
\end{property}

\begin{remark}
	Most of the results involve Stieltjes transforms $m_{\mu}(z)$ of a real probability measure with support $\operatorname{supp}(\mu) \subset \bbR$. Since Stieltjes transforms are such that
	\begin{equation*}
		m_{\mu}(z)>0,\forall z<\inf\operatorname{supp}(\mu),\quad m_{\mu}(z)<0,\forall z>\sup \operatorname{supp}(\mu),\quad\Im[z] \Im\left[m_{\mu}(z)\right]>0,\ \text{if}\ z\in\mathbb{C}\backslash\bbR
	\end{equation*}
	it will be convenient in the following to consider the set of scalar pairs
	\begin{equation*}
		\begin{array}{c}
			\mathcal{Z}(\mathcal{A})=\left\{(z,m)\in\mathcal{A}\times\mathbb{C},(\Im[z]\Im[m]>0\text{ if } \Im[z] \neq 0)\ \text{or}\ \left(m>0\text{ if }z<\inf \mathcal{A}^{c} \cap \bbR\right)\right. \\
			\left.\ \text{or}\ \left(m<0\text{ if }z>\sup \mathcal{A}^{c} \cap \bbR\right)\right\}
		\end{array}
	\end{equation*}
\end{remark}

As a transform, $m_{\mu}$ has an inverse formula to recover $\mu$, as per the following result.

\begin{theorem}[Inverse Stieltjes Transform] \label{thm:inverse-stieltjes-transform}
	For $a,b$ continuity points of the probability measure $\mu$, we have
	\begin{equation}
		\mu\left([a,b]\right)=\frac{1}{\pi}\lim_{y\downarrow 0}\int_{a}^{b}\Im\left[m_{\mu}(x+\imath y)\right]\dif x
	\end{equation}
	Specially, if $\mu$ has a density $f$ at $x$, then
	\begin{equation}
		f(x)=\frac{1}{\pi}\lim_{y\downarrow 0}\Im\left[m_{\mu}(x+\imath y)\right]
	\end{equation}
	And, if $\mu$ has an isolated mass at $x$, then
	\begin{equation}
		\mu(\{x\})=\lim_{y \downarrow 0}-\imath y m_{\mu}(x+\imath y)
	\end{equation}
\end{theorem}

\begin{proof}
	\begin{equation*}
		\begin{aligned}
			\frac{1}{\pi}\int_{a}^{b}\Im\left[m_{\mu}(x+\imath y)\right]\dif x= & \frac{1}{\pi}\int_{a}^{b}\left\{\int\Im\left[\frac{1}{(t-x)-\imath y}\right]\mu(\dif t)\right\}\dif x \\
			=                                                                   & \frac{1}{\pi}\int_{a}^{b}\left[\int\frac{y}{(t-x)^{2}+y^{2}}\mu(\dif t)\right]\dif x
		\end{aligned}
	\end{equation*}
	By Fubini theorem,
	\begin{equation*}
		\begin{aligned}
			= & \frac{1}{\pi}\int\left[\int_{a}^{b}\frac{y}{(t-x)^{2}+y^{2}}\dif x\right]\mu(\dif t)                         \\
			= & \frac{1}{\pi}\int\left[\arctan\left(\frac{b-t}{y}\right)-\arctan\left(\frac{a-t}{y}\right)\right]\mu(\dif t)
		\end{aligned}
	\end{equation*}

	Since
	\begin{equation*}
		\left|\frac{y}{(t-x)^{2}+y^{2}}\right|\leq\frac{1}{y},\quad\forall y>0
	\end{equation*}
	by the dominated convergence theorem,
	\begin{equation*}
		\frac{1}{\pi}\lim_{y\downarrow 0}\int_{a}^{b}\Im\left[m_{\mu}(x+\imath y)\right]\dif x=\frac{1}{\pi}\int\lim_{y\downarrow 0}\left[\arctan\left(\frac{b-t}{y}\right)-\arctan\left(\frac{a-t}{y}\right)\right]\mu(\dif t)
	\end{equation*}
	as $y\downarrow 0$, the difference in brackets converges either to $\pm \pi$ or 0 depending on the relative position of $a,b$ and $t$, thus
	\begin{equation*}
		=\int\mathrm{1}_{[a,b]}\mu(\dif t)=\mu\left([a,b]\right)
	\end{equation*}
	Thus, if $\mu$ has a density $f$ at $x$, then
	\begin{equation*}
		f(x)=\frac{1}{\pi}\lim_{y\downarrow 0}\Im\left[m_{\mu}(x+\imath y)\right]
	\end{equation*}

	When $\mu$ has an isolated mass at $x$, i.e., $\mu(d t)=a \delta_{x}(t)$, similarly, since
	\begin{equation*}
		|y(t-x)|\leq\frac{1}{2}\left(y^{2}+(t-x)^{2}\right)
	\end{equation*}
	by dominated convergence theorem,
	\begin{equation*}
		\lim_{y\downarrow 0}-\imath ym_{\mu}(x+\imath y)=-\lim_{y\downarrow 0}\int\frac{\imath y(t-x)\mu(\dif t)}{(t-x)^{2}+y^{2}}+\lim_{y\downarrow 0}\int\frac{y^{2}\mu(\dif t)}{(t-x)^{2}+y^{2}}=a
	\end{equation*}
\end{proof}

\begin{remark}
	The important relation between the empirical spectral measure $\mu_{\bfM}$ of $\bfM\in\bbR^{n\times n}$, the Stieltjes transform $m_{\mu_{\bfM}}(z)$ and the resolvent $\bfQ_{\bfM}(z)$ lies in the fact that
	\begin{equation} \label{eq:relation-between-empirical-spectral-measures-stieltjes-transform-and-its-resolvent}
		m_{\mu_{\bfM}}(z)=\frac{1}{n}\sum_{i=1}^{n}\int\frac{\delta_{\lambda_{i}(\bfM)}(t)}{t-z}=\frac{1}{n}\sum_{i=1}^{n}\frac{1}{\lambda_{i}(\bfM)-z}=\frac{1}{n}\operatorname{tr}\bfQ_{\bfM}(z)
	\end{equation}
\end{remark}

The resolvent $\bfQ_{\bfM}$ provides access to scalar observations of the eigenspectrum of $\bfM$ through its linear functionals. Cauchy's integral formula provides a connection between the linear functionals of the eigenvalues of $\bfM$ and the Stieltjes transform $m_{\mu_{\bfM}}(z)$ through
\begin{equation}
	\frac{1}{n}\sum_{i=1}^{n}f\left(\lambda_{i}(\bfM)\right)=-\frac{1}{2\pi\imath n}\oint_{\Gamma}f(z)\operatorname{tr}\left(\bfQ_{\bfM}(z)\right)\dif z=-\frac{1}{2\pi\imath }\oint_{\Gamma}f(z)m_{\mu_{\bfM}}(z)\dif z
\end{equation}
for all $f$ complex analytic in a compact neighborhood of $\operatorname{supp}\left(\mu_{\bfM}\right)$, by choosing the contour $\Gamma$ to enclose $\operatorname{supp}\left(\mu_{\bfM}\right)$ (i.e., all the eigenvalues $\lambda_{i}(\bfM)$).

\section{Matrix Equivalents}

\begin{definition}[Deterministic Equivalent]
	$\overline{\bfQ}\in\bbR^{n\times n}$ is said to be deterministic equivalent for the symmetric random matrix $\bfQ\in\bbR^{n\times n}$, if for a (sequences of) deterministic matrix $\bfA\in\bbR^{n\times n}$ and vectors $\bfa,\bfb\in\bbR^{n}$ of unit norms (operator and Euclidean, respectively),
	\begin{equation}
		\frac{1}{n}\operatorname{tr}\bfA(\bfQ-\overline{\bfQ})\rightarrow 0,\quad\bfa^{\prime}(\bfQ-\overline{\bfQ})\bfb\rightarrow 0,\ \text{as}\ n\rightarrow\infty
	\end{equation}
	where the convergence is either in probability or almost sure.
\end{definition}

\begin{remark}
	A practical use of deterministic equivalents is to establish that, for a random matrix $\bfM$ of interest, suppose
	\begin{equation*}
		\frac{1}{n}\operatorname{tr}\left(\bfQ_{\bfM}(z)-\overline{\bfQ}(z)\right)\rightarrow 0,\quad\text{a.s.},\quad\forall z\in\mathcal{C} ,\mathcal{C}\subset\mathbb{C}
	\end{equation*}
	this convergence implies that the Stieltjes transform of $\mu_{\mathrm{M}}$ "converges" in the sense that
	\begin{equation*}
		m_{\mu_{\mathrm{M}}}(z)-\bar{m}_{n}(z)\rightarrow 0
	\end{equation*}
	where $\bar{m}_{n}(z)=\frac{1}{n}\operatorname{tr}\overline{\bfQ}(z)$.
\end{remark}

\begin{definition}[Matrix Equivalents]
	For $\bfx,\mathbf{Y}\in\bbR^{n \times n}$ two random or deterministic matrices, we write
	\begin{equation}
		\bfx\leftrightarrow\mathbf{Y}
	\end{equation}
	if, for all $\bfA\in\bbR^{n\times n}$ and $\bfa,\bfb\in\bbR^{n}$ of unit norms (respectively, operator and Euclidean), we have the simultaneous results
	\begin{equation*}
		\frac{1}{n}\operatorname{tr}\bfA(\bfx-\mathbf{Y})\rightarrow 0,\quad \bfa^{\prime}(\bfx-\mathbf{Y})\bfb\rightarrow 0,\quad\|\bbE[\bfx-\mathbf{Y}]\|\rightarrow 0
	\end{equation*}
	where, for random quantities, the convergence is either in probability or almost sure.
\end{definition}

\section{Resolvent and Perturbation Identities}

\begin{lemma}[Resolvent Identity] \label{lem:resolvent-identity}
	For invertible matrices $\bfA$ and $\bfB$, we have
	\begin{equation}
		\bfA^{-1}-\bfB^{-1}=\bfA^{-1}\left(\bfB-\bfA\right)\bfB^{-1}
	\end{equation}
\end{lemma}

\begin{lemma}[Sherman-Morrison] \label{lem:sherman-morrison}
	For $\bfA\in\bbR^{n\times n}$ invertible and $\bfu,\bfv\in\bbR^{n}$, then $\bfA+\bfu\bfv^{\prime}$ is invertible if and only if $1+\bfv^{\prime}\bfA^{-1}\bfu\neq 0$ and
	\begin{equation}
		\left(\bfA+\bfu\bfv^{\prime}\right)^{-1}=\bfA^{-1}-\frac{\bfA^{-1}\bfu\bfv^{\prime}\bfA^{-1}}{1+\bfv^{\prime}\bfA^{-1}\bfu}
	\end{equation}
	or,
	\begin{equation}
		\left(\bfA+\bfu\bfv^{\prime}\right)^{-1}\bfu=\frac{\bfA^{-1}\bfu}{1+\bfv^{\prime}\bfA^{-1}\bfu}
	\end{equation}
\end{lemma}

\begin{lemma}[Quadratic-form-close-to-the-trace] \label{lem:quadratic-form-close-to-the-trace}
	Let $\bfx \in \bbR^{p}$ have iid entries of zero mean, unit variance and $\bbE\left[\left|x_{i}\right|^{K}\right] \leq \nu_{K}$ for some $K \geq 1$. Then for $\bfA \in \bbR^{p \times p}$ and $k \geq 1$
	$$
		\bbE\left[\left|\bfx^{\top} \bfA \bfx-\operatorname{tr} \bfA\right|^{k}\right] \leq C_{k}\left[\left(\nu_{4} \operatorname{tr}\left(\bfA \bfA^{\prime}\right)\right)^{k / 2}+\nu_{2 k} \operatorname{tr}\left(\bfA \bfA^{\prime}\right)^{k / 2}\right]
	$$
	for some constant $C_{k}>0$ independent of $p$. In particular, if $\|\bfA\| \leq 1$ and the entries of $\mathrm{x}$ have bounded eighth-order moment,
	$$
		\bbE\left[\left(\bfx^{\top} \bfA \bfx-\operatorname{tr} \bfA\right)^{4}\right] \leq C p^{2}
	$$
	for some $C>0$ independent of $p$, and consequently, as $p \rightarrow \infty$,
	$$
		\frac{1}{p} \bfx^{\top} \bfA \bfx-\frac{1}{p} \operatorname{tr} \bfA \stackrel{\text {a.s.}}{\longrightarrow} 0
	$$
\end{lemma}
