\chapter{Preliminary}

\section{Empirical Spectral Measure}

\begin{definition}[Empirical Spectral Measure]
	For a symmetric matrix \(\bfM\in\bbR^{n\times n}\), the spectral measure or empirical spectral measure or empirical spectral distribution (ESD) \(\mu_{\bfM}\) of \(\bfM\) is defined as the normalized counting measure of the eigenvalues \(\lambda_{1}(\bfM),\ldots,\lambda_{n}(\bfM)\) of \(\bfM\), i.e.,
	\begin{equation}
		\mu_{\bfM}:=\frac{1}{n}\sum_{i=1}^{n}\delta_{\lambda_{i}(\bfM)}
	\end{equation}
	where \(\delta_{x}\) is a Dirac measure for any (measurable) set, that
	\begin{equation*}
		\delta_{x}(A):=\mathbf{1}_{A}(x)=
		\begin{cases}
			0, & x\notin A \\
			1, & x\in A
		\end{cases}
	\end{equation*}
	Since \(\int\mu_{\bfM}\left(\dif x\right)=1\), the spectral measure \(\mu_{\bfM}\) of a matrix \(\bfM\in\bbR^{n\times n}\) (random or not) is a probability measure.
\end{definition}

\begin{remark}
	Many important statistics in multivariate analysis can be expressed as functionals of the ESD, such as, for \(\bfM\) be an \(n\times n\) positive definite matrix, then
	\begin{equation}
		\det(\bfM)=\prod_{i=1}^{n}\lambda_{i}=\exp\left(n\int_{0}^{\infty}\log x\mu_{\bfM}(\dif x)\right)
	\end{equation}
\end{remark}

\section{Stieltjes Transform}

\begin{definition}[Resolvent]
	For a symmetric matrix \(\bfM\in\bbR^{n\times n}\), the resolvent \(\bfQ_{\bfM}(z)\) of \(\bfM\) is defined as
	\begin{equation}
		\bfQ_{\bfM}(z):=\left(\bfM-z\mathbf{I}_{n}\right)^{-1}
	\end{equation}
	where \(z\in\mathbb{C}\) not eigenvalue of \(\bfM\).
\end{definition}

\begin{definition}[Stieltjes Transform]
	For a real probability measure \(\mu\) with support \(\operatorname{supp}(\mu)\), the Stieltjes transform \(m_{\mu}(z)\) is defined as
	\begin{equation}
		m_{\mu}(z):=\int\frac{1}{t-z}\mu\left(\dif t\right)
	\end{equation}
	where \(z\in\mathbb{C}\backslash\operatorname{supp}(\mu)\).
\end{definition}

\begin{property}
	The Stieltjes transform \(m_{\mu}\) has numerous interesting properties:
	\begin{enumerate}
		\item it is complex analytic on its domain of definition \(\mathbb{C} \backslash \operatorname{supp}(\mu)\).
		\item it is bounded \(\left|m_{\mu}(z)\right|\leq 1/\operatorname{dist}(z,\operatorname{supp}(\mu))\).
		\item it satisfies \(\Im[z]>0 \Rightarrow \Im[m(z)]>0\).
		\item it is an increasing function on all connected components of its restriction to \(\bbR\backslash\operatorname{supp}(\mu)\). % (since \(m_{\mu}^{\prime}(x)=\int(t-x)^{-2} \mu(d t)>0\))
		\item if \(\operatorname{supp}(\mu)\) is bounded, \(\lim_{x\rightarrow\pm\infty}m_{\mu}(x)=0\).
	\end{enumerate}
\end{property}

\begin{remark}
	Most of the results involve Stieltjes transforms \(m_{\mu}(z)\) of a real probability measure with support \(\operatorname{supp}(\mu) \subset \bbR\). Since Stieltjes transforms are such that
	\begin{equation*}
		m_{\mu}(z)>0,\forall z<\inf\operatorname{supp}(\mu),\quad m_{\mu}(z)<0,\forall z>\sup \operatorname{supp}(\mu),\quad\Im[z] \Im\left[m_{\mu}(z)\right]>0,\ \text{if}\ z\in\mathbb{C}\backslash\bbR
	\end{equation*}
	it will be convenient in the following to consider the set of scalar pairs
	\begin{equation*}
		\begin{array}{c}
			\mathcal{Z}(\mathcal{A})=\left\{(z,m)\in\mathcal{A}\times\mathbb{C},(\Im[z]\Im[m]>0\text{ if } \Im[z] \neq 0)\ \text{or}\ \left(m>0\text{ if }z<\inf \mathcal{A}^{c} \cap \bbR\right)\right. \\
			\left.\ \text{or}\ \left(m<0\text{ if }z>\sup \mathcal{A}^{c} \cap \bbR\right)\right\}
		\end{array}
	\end{equation*}
\end{remark}

As a transform, \(m_{\mu}\) has an inverse formula to recover \(\mu\), as per the following result.

\begin{theorem}[Inverse Stieltjes Transform]\label{thm:inverse-stieltjes-transform}
	For \(a,b\) continuity points of the probability measure \(\mu\), we have
	\begin{equation}
		\mu\left([a,b]\right)=\frac{1}{\pi}\lim_{y\downarrow 0}\int_{a}^{b}\Im\left[m_{\mu}(x+\imath y)\right]\dif x
	\end{equation}
	Specially, if \(\mu\) has a density \(f\) at \(x\), then
	\begin{equation}
		f(x)=\frac{1}{\pi}\lim_{y\downarrow 0}\Im\left[m_{\mu}(x+\imath y)\right]
	\end{equation}
	And, if \(\mu\) has an isolated mass at \(x\), then
	\begin{equation}
		\mu(\{x\})=\lim_{y \downarrow 0}-\imath y m_{\mu}(x+\imath y)
	\end{equation}
\end{theorem}

\begin{proof}
	\begin{equation*}
		\begin{aligned}
			\frac{1}{\pi}\int_{a}^{b}\Im\left[m_{\mu}(x+\imath y)\right]\dif x= & \frac{1}{\pi}\int_{a}^{b}\left\{\int\Im\left[\frac{1}{(t-x)-\imath y}\right]\mu(\dif t)\right\}\dif x \\
			=                                                                   & \frac{1}{\pi}\int_{a}^{b}\left[\int\frac{y}{(t-x)^{2}+y^{2}}\mu(\dif t)\right]\dif x
		\end{aligned}
	\end{equation*}
	By Fubini theorem,
	\begin{equation*}
		\begin{aligned}
			= & \frac{1}{\pi}\int\left[\int_{a}^{b}\frac{y}{(t-x)^{2}+y^{2}}\dif x\right]\mu(\dif t)                         \\
			= & \frac{1}{\pi}\int\left[\arctan\left(\frac{b-t}{y}\right)-\arctan\left(\frac{a-t}{y}\right)\right]\mu(\dif t)
		\end{aligned}
	\end{equation*}

	Since
	\begin{equation*}
		\left|\frac{y}{(t-x)^{2}+y^{2}}\right|\leq\frac{1}{y},\quad\forall y>0
	\end{equation*}
	by the dominated convergence theorem,
	\begin{equation*}
		\frac{1}{\pi}\lim_{y\downarrow 0}\int_{a}^{b}\Im\left[m_{\mu}(x+\imath y)\right]\dif x=\frac{1}{\pi}\int\lim_{y\downarrow 0}\left[\arctan\left(\frac{b-t}{y}\right)-\arctan\left(\frac{a-t}{y}\right)\right]\mu(\dif t)
	\end{equation*}
	as \(y\downarrow 0\), the difference in brackets converges either to \(\pm \pi\) or 0 depending on the relative position of \(a,b\) and \(t\), thus
	\begin{equation*}
		=\int\mathrm{1}_{[a,b]}\mu(\dif t)=\mu\left([a,b]\right)
	\end{equation*}
	Thus, if \(\mu\) has a density \(f\) at \(x\), then
	\begin{equation*}
		f(x)=\frac{1}{\pi}\lim_{y\downarrow 0}\Im\left[m_{\mu}(x+\imath y)\right]
	\end{equation*}

	When \(\mu\) has an isolated mass at \(x\), i.e., \(\mu(d t)=a \delta_{x}(t)\), similarly, since
	\begin{equation*}
		|y(t-x)|\leq\frac{1}{2}\left(y^{2}+(t-x)^{2}\right)
	\end{equation*}
	by dominated convergence theorem,
	\begin{equation*}
		\lim_{y\downarrow 0}-\imath ym_{\mu}(x+\imath y)=-\lim_{y\downarrow 0}\int\frac{\imath y(t-x)\mu(\dif t)}{(t-x)^{2}+y^{2}}+\lim_{y\downarrow 0}\int\frac{y^{2}\mu(\dif t)}{(t-x)^{2}+y^{2}}=a
	\end{equation*}
\end{proof}

\begin{remark}
	The important relation between the empirical spectral measure \(\mu_{\bfM}\) of \(\bfM\in\bbR^{n\times n}\), the Stieltjes transform \(m_{\mu_{\bfM}}(z)\) and the resolvent \(\bfQ_{\bfM}(z)\) lies in the fact that
	\begin{equation} \label{eq:relation-between-empirical-spectral-measures-stieltjes-transform-and-its-resolvent}
		m_{\mu_{\bfM}}(z)=\frac{1}{n}\sum_{i=1}^{n}\int\frac{\delta_{\lambda_{i}(\bfM)}(t)}{t-z}=\frac{1}{n}\sum_{i=1}^{n}\frac{1}{\lambda_{i}(\bfM)-z}=\frac{1}{n}\operatorname{tr}\bfQ_{\bfM}(z)
	\end{equation}
\end{remark}

The resolvent \(\bfQ_{\bfM}\) provides access to scalar observations of the eigenspectrum of \(\bfM\) through its linear functionals. Cauchy's integral formula provides a connection between the linear functionals of the eigenvalues of \(\bfM\) and the Stieltjes transform \(m_{\mu_{\bfM}}(z)\) through
\begin{equation}
	\frac{1}{n}\sum_{i=1}^{n}f\left(\lambda_{i}(\bfM)\right)=-\frac{1}{2\pi\imath n}\oint_{\Gamma}f(z)\operatorname{tr}\left(\bfQ_{\bfM}(z)\right)\dif z=-\frac{1}{2\pi\imath }\oint_{\Gamma}f(z)m_{\mu_{\bfM}}(z)\dif z
\end{equation}
for all \(f\) complex analytic in a compact neighborhood of \(\operatorname{supp}\left(\mu_{\bfM}\right)\), by choosing the contour \(\Gamma\) to enclose \(\operatorname{supp}\left(\mu_{\bfM}\right)\) (i.e., all the eigenvalues \(\lambda_{i}(\bfM)\)).

\section{Matrix Equivalents}

\begin{definition}[Deterministic Equivalent]
	\(\overline{\bfQ}\in\bbR^{n\times n}\) is said to be deterministic equivalent for the symmetric random matrix \(\bfQ\in\bbR^{n\times n}\), if for a (sequences of) deterministic matrix \(\bfA\in\bbR^{n\times n}\) and vectors \(\bfa,\bfb\in\bbR^{n}\) of unit norms (operator and Euclidean, respectively),
	\begin{equation}
		\frac{1}{n}\operatorname{tr}\bfA(\bfQ-\overline{\bfQ})\rightarrow 0,\quad\bfa^{\prime}(\bfQ-\overline{\bfQ})\bfb\rightarrow 0,\ \text{as}\ n\rightarrow\infty
	\end{equation}
	where the convergence is either in probability or almost sure.
\end{definition}

\begin{remark}
	A practical use of deterministic equivalents is to establish that, for a random matrix \(\bfM\) of interest, suppose
	\begin{equation*}
		\frac{1}{n}\operatorname{tr}\left(\bfQ_{\bfM}(z)-\overline{\bfQ}(z)\right)\rightarrow 0,\quad\text{a.s.},\quad\forall z\in\mathcal{C} ,\mathcal{C}\subset\mathbb{C}
	\end{equation*}
	this convergence implies that the Stieltjes transform of \(\mu_{\mathrm{M}}\) ``converges'' in the sense that
	\begin{equation*}
		m_{\mu_{\mathrm{M}}}(z)-\bar{m}_{n}(z)\rightarrow 0
	\end{equation*}
	where \(\bar{m}_{n}(z)=\frac{1}{n}\operatorname{tr}\overline{\bfQ}(z)\).
\end{remark}

\begin{definition}[Matrix Equivalents]
	For \(\bfx,\mathbf{Y}\in\bbR^{n \times n}\) two random or deterministic matrices, we write
	\begin{equation}
		\bfx\leftrightarrow\mathbf{Y}
	\end{equation}
	if, for all \(\bfA\in\bbR^{n\times n}\) and \(\bfa,\bfb\in\bbR^{n}\) of unit norms (respectively, operator and Euclidean), we have the simultaneous results
	\begin{equation*}
		\frac{1}{n}\operatorname{tr}\bfA(\bfx-\mathbf{Y})\rightarrow 0,\quad \bfa^{\prime}(\bfx-\mathbf{Y})\bfb\rightarrow 0,\quad\|\bbE[\bfx-\mathbf{Y}]\|\rightarrow 0
	\end{equation*}
	where, for random quantities, the convergence is either in probability or almost sure.
\end{definition}

\section{Resolvent and Perturbation Identities}

\begin{lemma}[Resolvent Identity]\label{lem:resolvent-identity}
	For invertible matrices \(\bfA\) and \(\bfB\), we have
	\begin{equation}
		\bfA^{-1}-\bfB^{-1}=\bfA^{-1}\left(\bfB-\bfA\right)\bfB^{-1}
	\end{equation}
\end{lemma}

\begin{lemma}[Sherman-Morrison]\label{lem:sherman-morrison}
	For \(\bfA\in\bbR^{n\times n}\) invertible and \(\bfu,\bfv\in\bbR^{n}\), then \(\bfA+\bfu\bfv^{\prime}\) is invertible if and only if \(1+\bfv^{\prime}\bfA^{-1}\bfu\neq 0\) and
	\begin{equation}
		\left(\bfA+\bfu\bfv^{\prime}\right)^{-1}=\bfA^{-1}-\frac{\bfA^{-1}\bfu\bfv^{\prime}\bfA^{-1}}{1+\bfv^{\prime}\bfA^{-1}\bfu}
	\end{equation}
	or,
	\begin{equation}
		\left(\bfA+\bfu\bfv^{\prime}\right)^{-1}\bfu=\frac{\bfA^{-1}\bfu}{1+\bfv^{\prime}\bfA^{-1}\bfu}
	\end{equation}
\end{lemma}

\begin{lemma}[Quadratic-form-close-to-the-trace]\label{lem:quadratic-form-close-to-the-trace}
	Let \(\bfx \in \bbR^{p}\) have iid entries of zero mean, unit variance and \(\bbE\left[\left|x_{i}\right|^{K}\right] \leq \nu_{K}\) for some \(K \geq 1\). Then for \(\bfA \in \bbR^{p \times p}\) and \(k \geq 1\)
	\begin{equation*}
		\bbE\left[\left|\bfx^{\top} \bfA \bfx-\operatorname{tr} \bfA\right|^{k}\right] \leq C_{k}\left[\left(\nu_{4} \operatorname{tr}\left(\bfA \bfA^{\prime}\right)\right)^{k / 2}+\nu_{2 k} \operatorname{tr}\left(\bfA \bfA^{\prime}\right)^{k / 2}\right]
	\end{equation*}
	for some constant \(C_{k}>0\) independent of \(p\). In particular, if \(\|\bfA\| \leq 1\) and the entries of \(\mathrm{x}\) have bounded eighth-order moment,
	\begin{equation*}
		\bbE\left[\left(\bfx^{\top} \bfA \bfx-\operatorname{tr} \bfA\right)^{4}\right] \leq C p^{2}
	\end{equation*}
	for some \(C>0\) independent of \(p\), and consequently, as \(p \rightarrow \infty\),
	\begin{equation*}
		\frac{1}{p} \bfx^{\top} \bfA \bfx-\frac{1}{p} \operatorname{tr} \bfA \stackrel{\text {a.s.}}{\longrightarrow} 0
	\end{equation*}
\end{lemma}
