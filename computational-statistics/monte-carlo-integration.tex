\chapter{Monte Carlo Integration}

Suppose we want to estimate the expectation of a function \(h(x)\) for a probability distribution \(\pi(x)\), i.e., we want to estimate
\begin{equation}
	\mu=\bbE_{\pi}[h(x)]=\int h(x)\pi(x)\dif x.
\end{equation}

\section{Monte Carlo Integration}

If we can sample from \(\pi(x)\), then we can use the Monte Carlo integration method as follows:
\begin{equation}
	\hat{\mu}=\frac{1}{N}\sum_{i=1}^{N}h(x_{i}),
\end{equation}
where \(x_{i}\sim\pi(x),\quad i=1,\ldots,N\).

\section{Importance Sampling}

Importance sampling is a variance reduction technique that can be used when sampling from a distribution \(\pi(x)\) is difficult, but sampling from a distribution \(g(x)\) is easy. The idea is to sample from \(g(x)\) and then reweight the samples so that they are distributed according to \(\pi(x)\).

If the probability distribution \(\pi(x)\) is difficult to sample from, we can find a proposal distribution \(g(x)\). Then the Importance sampling method is as follows:

\begin{algorithm}[H]
	\caption{Importance Sampling Method}
	\KwIn{Proposal distribution \(g(x)\), number of samples \(N\)}
	\For{\(i=1,\ldots,N\)}{
		Draw a sample \(x_{i}\sim g(x)\)\;
		Compute \(w_{i}=\frac{\pi(x_{i})}{g(x_{i})}\)\;
	}
	Calculate \(\hat{\mu}=\frac{1}{N}\sum_{i=1}^{N}w_{i}h(x_{i})\)\;
	\KwOut{Estimate \(\hat{\mu}\)}
\end{algorithm}

\paragraph{Normalized Importance Sampling}

If we do not know the normalization constant of \(\pi(x)\), we can use the normalized importance sampling method as follows:
\begin{equation}
	\hat{\mu}=\frac{\sum_{i=1}^{N}w_{i}h(x_{i})}{\sum_{i=1}^{N}w_{i}}.
\end{equation}
