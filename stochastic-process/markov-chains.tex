\chapter{Markov Chains}

\section{Markov Chain}

\begin{definition}[Markov Chain, Simple]
    A sequence $\left\{X_{n}\right\}$ of real-valued random variables  is said to be a Markov chain, if for any states $i_{0},\ldots i_{n-1},i$, and $j$
    \begin{equation}
        P\left(X_{n+1}=j\mid X_{n}=i,X_{n-1}=i_{n-1},\ldots X_{0}=i_{0}\right)=P\left(X_{n+1}=j\mid X_{n}=i\right)
    \end{equation}
    and the transition probability is
    \begin{equation}
        p(i,j)=P\left(X_{n+1}=j\mid X_{n}=i\right)
    \end{equation}
\end{definition}

\begin{example}[ Random Walk]
    Suppose $X_{n}=X_{0}+\xi_{1}+\cdots+\xi_{n}$, where $X_{0}$ is constant, $\xi_{m}\in\mathbb{Z}^{d}$ are independent with distribution $\mu$. Show $X_{n}$ is a Markov chain with transition probability,
    \begin{equation*}
        p\left(i,j\right)=\mu\left(\left\{j-i\right\}\right)
    \end{equation*}
\end{example}

\begin{proof}
    Since $\xi_{m}$ are independent with distribution $\mu$,
    \begin{equation*}
        \begin{aligned}
              & P\left(X_{n+1}=j\mid X_{n}=i,X_{n-1}=i_{n-1},\ldots X_{0}=i_{0}\right)                                     \\
            = & P\left(X_{n}+\xi_{n+1}=j\mid X_{n}=i\right)=P\left(\xi_{n+1}=j-i\right)=\mu\left(\left\{j-i\right\}\right)
        \end{aligned}
    \end{equation*}
\end{proof}

\begin{definition}[Branching Processes]
    Let $\xi_{i}^{n},i,n\geq 1$, be i.i.d. nonnegative integer-valued random variables. Define a sequence $Z_{n},n\geq 0$ by $Z_{0}=1$ and
    \begin{equation}
        Z_{n+1}=\left\{\begin{array}{ll}
            \xi_{1}^{n+1}+\cdots+\xi_{Z_{n}}^{n+1} & Z_{n}>0 \\
            0                                      & Z_{n}=0
        \end{array}\right.
    \end{equation}
    $Z_{n}$ is called a Branching process.
\end{definition}

\begin{note}
    The idea behind the definitions is that $Z_{n}$ is the number of individuals in the $n$-th generation, and each member of the $n$-th generation gives birth independently to an identically distributed number of children.
\end{note}

\begin{example}[ Branching Processes]
    Show branching process is a Markov chain with transition probability,
    \begin{equation*}
        p(i,j)=P\left(\sum_{k=1}^{i}\xi_{k}=j\right)
    \end{equation*}
\end{example}

\begin{proof}
    Since $\xi_{k}^{n}$ are independent with identically distribution,
    \begin{equation*}
        \begin{aligned}
              & P\left(Z_{n+1}=j\mid Z_{n}=i,Z_{n-1}=i_{n-1},\ldots Z_{0}=i_{0}\right)                            \\
            = & P\left(\sum_{k=1}^{Z_{n}}\xi_{k}^{n+1}=j\mid Z_{n}=i\right)=P\left(\sum_{k=1}^{i}\xi_{k}=j\right)
        \end{aligned}
    \end{equation*}
\end{proof}

Suppose $(S, \mathcal{S})$ be a measurable space, which will be the state space for our Markov chain.

\begin{definition}[Transition Probability]
    A function $p:S\times\mathcal{S}\rightarrow\mathbf{R}$ is said to be a transition probability, if
    \begin{enumerate}
        \item For each $x\in S$, $A\rightarrow p(x,A)$ is a probability measure on $(S,\mathcal{S})$
        \item For each $A\in\mathcal{S}$, $x\rightarrow p(x,A)$ is a measurable function
    \end{enumerate}
\end{definition}
\begin{definition}[Markov Chain]
    A sequence $\left\{X_{n}\right\}$ of real-valued random variables with transition probability $p$ is said to be a Markov chain with respect to $\mathcal{F}_{n}$, if
    \begin{equation}
        P\left(X_{n+1}\in B\mid\mathcal{F}_{n}\right)=p\left(X_{n},B\right)
    \end{equation}
\end{definition}

\begin{remark}
    Given a transition probability $p$ and an initial distribution $\mu$ on $(S,\mathcal{S})$, the consistent set of finite dimensional distributions is
    \begin{equation}
        P\left(X_{j}\in B_{j},0\leq j\leq n\right)=\int_{B_{0}}\mu\left(\,\mathrm{d}x_{0}\right)\int_{B_{1}}p\left(x_{0},\,\mathrm{d}x_{1}\right)\cdots\int_{B_{n}}p\left(x_{n-1},\,\mathrm{d}x_{n}\right)
        F    \end{equation}
\end{remark}

\section{Markov Properties}

\begin{theorem}[Markov Property]

\end{theorem}

\begin{corollary}[Chapman-Kolmogorov Equation]

\end{corollary}

\begin{theorem}[Strong Markov Property]

\end{theorem}

\section{Recurrence and Transience}

Let $T_{y}^{0}=0$, and for $k\geq 1$, and
\begin{equation}
    T_{y}^{k}=\inf\left\{n>T_{y}^{k-1}:X_{n}=y\right\}
\end{equation}
then $T_{y}^{k}$ is the time of the $k$-th return to $y$, where $T_{y}^{1}>0$, so any visit at time 0 does not count.

Let
\begin{equation}
    \rho_{x y}=P_{x}\left(T_{y}<\infty\right)
\end{equation}
and we have
\begin{equation}
    P_{x}\left(T_{y}^{k}<\infty\right)=\rho_{xy}\rho_{yy}^{k-1}
\end{equation}

\begin{proof}

\end{proof}

Let
\begin{equation}
    N(y)=\sum_{n=1}^{\infty}1_{\left(X_{n}=y\right)}
\end{equation}
be the number of visits to $y$ at positive times.

\begin{definition}[Recurrent]
    A state $y$ is said to be recurrent if $\rho_{yy}=1$.
\end{definition}

\begin{property}
    The recurrent state $y$ has the following properties
    \begin{enumerate}
        \item $y$ is recurrent if and only if
              \begin{equation*}
                  E_{y}N(y)=\infty.
              \end{equation*}
        \item If $x$ is recurrent and $\rho_{xy}>0$, then $y$ is recurrent and $\rho_{yx}=1$.
    \end{enumerate}
\end{property}

\begin{definition}
    A state $y$ is said to be transient if $\rho_{yy}<1$.
\end{definition}

\begin{property}
    The transient state $y$ has the following properties
    \begin{enumerate}
        \item If $y$ is transient, then
              \begin{equation*}
                  E_{x}N(y)<\infty,\quad\forall x.
              \end{equation*}
    \end{enumerate}
\end{property}

\begin{proof}
    \begin{equation*}
        \begin{aligned}
            E_{x}N(y) & =\sum_{k=1}^{\infty}P_{x}(N(y)\geq k)=\sum_{k=1}^{\infty}P_{x}\left(T_{y}^{k}<\infty\right) \\
                      & =\sum_{k=1}^{\infty}\rho_{xy}\rho_{yy}^{k-1}=\frac{\rho_{xy}}{1-\rho_{yy}}<\infty
        \end{aligned}
    \end{equation*}
\end{proof}

\begin{definition}[Closed State Set]
    A set $C$ of states is said to be closed, if
    \begin{equation}
        x\in C,\rho_{xy}>0\Rightarrow y\in C.
    \end{equation}
\end{definition}

\begin{definition}[Irreducible State Set]
    A set $D$ of states is said to be irreducible, if
    \begin{equation}
        x,y\in D\Rightarrow\rho_{xy}>0.
    \end{equation}
\end{definition}

\begin{theorem}
    Let $C$ be a finite closed set, then
    \begin{enumerate}
        \item $C$ contains a recurrent state.
        \item If $C$ is irreducible, then all states in $C$ are recurrent.
    \end{enumerate}
\end{theorem}

\begin{theorem}
    Suppose $C_{x}=\left\{y:\rho_{x y}>0\right\}$, then $C_{x}$ is an irreducible closed set.
\end{theorem}

\begin{proof}
    If $y,z\in C_{x}$, then $\rho_{yz}\geq\rho_{yx}\rho_{xz}>0$. If $\rho_{yw}>0$, then $\rho_{xw}\geq\rho_{xy}\rho_{yw}>0$, so $w\in C_{x}$.
\end{proof}

\begin{example}[ A Seven-state Chain]
    Consider the transition probability,
    \begin{equation*}
        \begin{array}{cccccccc}
                       & \mathbf{1} & \mathbf{2} & \mathbf{3} & \mathbf{4} & \mathbf{5} & \mathbf{6} & \mathbf{7} \\
            \mathbf{1} & .3         & 0          & 0          & 0          & .7         & 0          & 0          \\
            \mathbf{2} & .1         & .2         & .3         & .4         & 0          & 0          & 0          \\
            \mathbf{3} & 0          & 0          & .5         & .5         & 0          & 0          & 0          \\
            \mathbf{4} & 0          & 0          & 0          & .5         & 0          & .5         & 0          \\
            \mathbf{5} & .6         & 0          & 0          & 0          & .4         & 0          & 0          \\
            \mathbf{6} & 0          & 0          & 0          & .1         & 0          & .1         & .8         \\
            \mathbf{7} & 0          & 0          & 0          & 1          & 0          & 0          & 0
        \end{array}
    \end{equation*}
    try to identify the states that are recurrent and those that are transient.
\end{example}

\begin{proof}
    $\{2,3\}$ are transition states, and $\{1,4,5,6,7\}$ are recurrent states.
\end{proof}

\begin{remark}
    Suppose $S$ is finite, for $x\in S$,
    \begin{enumerate}
        \item $x$ is transient, if
              \begin{equation*}
                  \exists y,\text{ s.t. }\quad\rho_{xy}>0,\rho_{yx}=0
              \end{equation*}
        \item $x$ is recurrent, if
              \begin{equation*}
                  \exists y,\text{ s.t. }\quad\rho_{xy}>0,\rho_{yx}>0
              \end{equation*}
    \end{enumerate}
\end{remark}

% Theorem 5.2.6 implies $P_{y}\left(T_{y}^{k}<\infty\right)=1$ for all $k$, so $P_{y}\left(X_{n}=y\text{ i.o. }\right)=1$.

\section{Stationary Measures}

\section{Asymptotic Behavior}

\section{Ergodic Theorems}

\begin{definition}[Stationary Sequence]

\end{definition}

\begin{theorem}[Ergodic Theorem]

\end{theorem}

\begin{example}

\end{example}