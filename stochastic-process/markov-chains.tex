\chapter{Markov Chains}

\section{Markov Chain}

\begin{definition}[Markov Chain, Simple]
	A sequence \(\left\{X_{n}\right\}\) of real-valued random variables  is said to be a Markov chain, if for any states \(i_{0},\ldots i_{n-1},i\), and \(j\)
	\begin{equation}
		P\left(X_{n+1}=j\mid X_{n}=i,X_{n-1}=i_{n-1},\ldots X_{0}=i_{0}\right)=P\left(X_{n+1}=j\mid X_{n}=i\right)
	\end{equation}
	and the transition probability is
	\begin{equation}
		p(i,j)=P\left(X_{n+1}=j\mid X_{n}=i\right)
	\end{equation}
\end{definition}

\begin{example}[Random Walk]
	Suppose \(X_{n}=X_{0}+\xi_{1}+\cdots+\xi_{n}\), where \(X_{0}\) is constant, \(\xi_{m}\in\mathbb{Z}^{d}\) are independent with distribution \(\mu\). Show \(X_{n}\) is a Markov chain with transition probability,
	\begin{equation*}
		p\left(i,j\right)=\mu\left(\left\{j-i\right\}\right)
	\end{equation*}
\end{example}

\begin{proof}
	Since \(\xi_{m}\) are independent with distribution \(\mu\),
	\begin{equation*}
		\begin{aligned}
			  & P\left(X_{n+1}=j\mid X_{n}=i,X_{n-1}=i_{n-1},\ldots X_{0}=i_{0}\right)                                     \\
			= & P\left(X_{n}+\xi_{n+1}=j\mid X_{n}=i\right)=P\left(\xi_{n+1}=j-i\right)=\mu\left(\left\{j-i\right\}\right)
		\end{aligned}
	\end{equation*}
\end{proof}

\begin{definition}[Branching Processes]
	Let \(\xi_{i}^{n},i,n\geq 1\), be iid nonnegative integer-valued random variables. Define a sequence \(Z_{n},n\geq 0\) by \(Z_{0}=1\) and
	\begin{equation}
		Z_{n+1}=\left\{\begin{array}{ll}
			\xi_{1}^{n+1}+\cdots+\xi_{Z_{n}}^{n+1} & Z_{n}>0 \\
			0                                      & Z_{n}=0
		\end{array}\right.
	\end{equation}
	\(Z_{n}\) is called a Branching process.
\end{definition}

\begin{remark}
	The idea behind the definitions is that \(Z_{n}\) is the number of individuals in the \(n\)-th generation, and each member of the \(n\)-th generation gives birth independently to an identically distributed number of children.
\end{remark}

\begin{example}[Branching Processes]
	Show branching process is a Markov chain with transition probability,
	\begin{equation*}
		p(i,j)=P\left(\sum_{k=1}^{i}\xi_{k}=j\right)
	\end{equation*}
\end{example}

\begin{proof}
	Since \(\xi_{k}^{n}\) are independent with identically distribution,
	\begin{equation*}
		\begin{aligned}
			  & P\left(Z_{n+1}=j\mid Z_{n}=i,Z_{n-1}=i_{n-1},\ldots Z_{0}=i_{0}\right)                            \\
			= & P\left(\sum_{k=1}^{Z_{n}}\xi_{k}^{n+1}=j\mid Z_{n}=i\right)=P\left(\sum_{k=1}^{i}\xi_{k}=j\right)
		\end{aligned}
	\end{equation*}
\end{proof}

Suppose \((S, \mathcal{S})\) is a measurable space, which will be the state space for our Markov chain.

\begin{definition}[Transition Probability]
	A function \(p:S\times\mathcal{S}\rightarrow\bbR\) is said to be a transition probability, if
	\begin{enumerate}
		\item For each \(x\in S\), \(A\rightarrow p(x,A)\) is a probability measure on \((S,\mathcal{S})\)
		\item For each \(A\in\mathcal{S}\), \(x\rightarrow p(x,A)\) is a measurable function
	\end{enumerate}
\end{definition}
\begin{definition}[Markov Chain]
	A sequence \(\left\{X_{n}\right\}\) of real-valued random variables with transition probability \(p\) is said to be a Markov chain with respect to \(\mcF_{n}\), if
	\begin{equation}
		P\left(X_{n+1}\in B\mid\mcF_{n}\right)=p\left(X_{n},B\right)
	\end{equation}
\end{definition}

\begin{remark}
	Given a transition probability \(p\) and an initial distribution \(\mu\) on \((S,\mathcal{S})\), the consistent set of finite dimensional distributions is
	\begin{equation}
		P\left(X_{j}\in B_{j},0\leq j\leq n\right)=\int_{B_{0}}\mu\left(\dif x_{0}\right)\int_{B_{1}}p\left(x_{0},\dif x_{1}\right)\cdots\int_{B_{n}}p\left(x_{n-1},\dif x_{n}\right)
		F    \end{equation}
\end{remark}

\section{Markov Properties}

\begin{definition}[Shift Operator]

\end{definition}

\begin{theorem}[Markov Property]

\end{theorem}

\begin{corollary}[Chapman-Kolmogorov Equation]

\end{corollary}

\begin{theorem}[Strong Markov Property]

\end{theorem}

\section{Recurrence and Transience}

Let \(T_{y}^{0}=0\), and for \(k\geq 1\), and
\begin{equation}
	T_{y}^{k}=\inf\left\{n>T_{y}^{k-1}:X_{n}=y\right\}
\end{equation}
then \(T_{y}^{k}\) is the time of the \(k\)-th return to \(y\), where \(T_{y}^{1}>0\), so any visit at time 0 does not count.

Let
\begin{equation}
	\rho_{x y}=P_{x}\left(T_{y}<\infty\right)
\end{equation}
and we have
\begin{equation}
	P_{x}\left(T_{y}^{k}<\infty\right)=\rho_{xy}\rho_{yy}^{k-1}
\end{equation}

\begin{proof}

\end{proof}

Let
\begin{equation}
	N(y)=\sum_{n=1}^{\infty}1_{\left(X_{n}=y\right)}
\end{equation}
be the number of visits to \(y\) at positive times.

\begin{definition}[Recurrent]
	A state \(y\) is said to be recurrent if \(\rho_{yy}=1\).
\end{definition}

\begin{property}
	The recurrent state \(y\) has the following properties
	\begin{enumerate}
		\item \(y\) is recurrent if and only if
		      \begin{equation*}
			      E_{y}N(y)=\infty.
		      \end{equation*}
		\item If \(x\) is recurrent and \(\rho_{xy}>0\), then \(y\) is recurrent and \(\rho_{yx}=1\).
	\end{enumerate}
\end{property}

\begin{definition}
	A state \(y\) is said to be transient if \(\rho_{yy}<1\).
\end{definition}

\begin{property}
	The transient state \(y\) has the following properties
	\begin{enumerate}
		\item If \(y\) is transient, then
		      \begin{equation*}
			      E_{x}N(y)<\infty,\quad\forall x.
		      \end{equation*}
	\end{enumerate}
\end{property}

\begin{proof}
	\begin{equation*}
		\begin{aligned}
			E_{x}N(y) & =\sum_{k=1}^{\infty}P_{x}(N(y)\geq k)=\sum_{k=1}^{\infty}P_{x}\left(T_{y}^{k}<\infty\right) \\
			          & =\sum_{k=1}^{\infty}\rho_{xy}\rho_{yy}^{k-1}=\frac{\rho_{xy}}{1-\rho_{yy}}<\infty
		\end{aligned}
	\end{equation*}
\end{proof}

\begin{definition}[Closed State Set]
	A set \(C\) of states is said to be closed, if
	\begin{equation}
		x\in C,\rho_{xy}>0\Rightarrow y\in C.
	\end{equation}
\end{definition}

\begin{definition}[Irreducible State Set]
	A set \(D\) of states is said to be irreducible, if
	\begin{equation}
		x,y\in D\Rightarrow\rho_{xy}>0.
	\end{equation}
\end{definition}

\begin{theorem}
	Let \(C\) be a finite closed set, then
	\begin{enumerate}
		\item \(C\) contains a recurrent state.
		\item If \(C\) is irreducible, then all states in \(C\) are recurrent.
	\end{enumerate}
\end{theorem}

\begin{theorem}
	Suppose \(C_{x}=\left\{y:\rho_{x y}>0\right\}\), then \(C_{x}\) is an irreducible closed set.
\end{theorem}

\begin{proof}
	If \(y,z\in C_{x}\), then \(\rho_{yz}\geq\rho_{yx}\rho_{xz}>0\). If \(\rho_{yw}>0\), then \(\rho_{xw}\geq\rho_{xy}\rho_{yw}>0\), so \(w\in C_{x}\).
\end{proof}

\begin{example}[A Seven-state Chain]
	Consider the transition probability,
	\begin{equation*}
		\begin{array}{cccccccc}
			           & \mathbf{1} & \mathbf{2} & \mathbf{3} & \mathbf{4} & \mathbf{5} & \mathbf{6} & \mathbf{7} \\
			\mathbf{1} & 0.3        & 0          & 0          & 0          & 0.7        & 0          & 0          \\
			\mathbf{2} & 0.1        & 0.2        & 0.3        & 0.4        & 0          & 0          & 0          \\
			\mathbf{3} & 0          & 0          & 0.5        & 0.5        & 0          & 0          & 0          \\
			\mathbf{4} & 0          & 0          & 0          & 0.5        & 0          & 0.5        & 0          \\
			\mathbf{5} & 0.6        & 0          & 0          & 0          & 0.4        & 0          & 0          \\
			\mathbf{6} & 0          & 0          & 0          & 0.1        & 0          & 0.1        & 0.8        \\
			\mathbf{7} & 0          & 0          & 0          & 1          & 0          & 0          & 0
		\end{array}
	\end{equation*}
	try to identify the recurrent states and those that are transient.
\end{example}

\begin{proof}
	\(\{2,3\}\) are transition states, and \(\{1,4,5,6,7\}\) are recurrent states.
\end{proof}

\begin{remark}
	Suppose \(S\) is finite, for \(x\in S\),
	\begin{enumerate}
		\item \(x\) is transient, if
		      \begin{equation*}
			      \exists y,\rho_{xy}>0,\ \text{s.t.}\ \rho_{yx}=0
		      \end{equation*}
		\item \(x\) is recurrent, if
		      \begin{equation*}
			      \forall y,\rho_{xy}>0,\ \text{s.t.}\ \rho_{yx}>0
		      \end{equation*}
	\end{enumerate}
\end{remark}

% Theorem 5.2.6 implies \(P_{y}\left(T_{y}^{k}<\infty\right)=1\) for all \(k\), so \(P_{y}\left(X_{n}=y\text{ i.o. }\right)=1\).

\section{Stationary Measures}

\section{Asymptotic Behavior}

\section{Ergodic Theorems}

\begin{definition}[Stationary Sequence]

\end{definition}

\begin{theorem}[Ergodic Theorem]

\end{theorem}

\begin{example}

\end{example}
